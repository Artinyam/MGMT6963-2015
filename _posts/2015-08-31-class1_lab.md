---
layout: post
title:  "Lab 1: The Data Science Toolkit"
date:   2015-08-31 19:00:00
meeting: "1"
notes: ""
#readings: "There are no readings for today."
#assignment: "There is no assignment for today."
permalink: /classes/class1lab/
categories: "welcome tools"
header-img: "img/1_header.png"


---
## Doing Data Science - The Data Platform
When learning and doing data science, the *development environment* becomes the platform that you have to process and analyze data. The term comes from applications development in which development changes are typically moved from a development machine through to a testing environment and eventually to the production application. While traditionally statistics research has been developed and analyzed within a single local machine and maybe a single program, increasingly analytics apps are deployed in such a way that the data is *actively* used and processing of the data employs a wide variety of packages and programs.  This can include use in a dashboard,  can be deployed within a production environment, providing such things as forecasts or pricing changes that are directly acted upon in a transactional system.  In these types of contexts, there is good reason to try to make the development environment as close to the production environment as possible and to employ techniques .  Similar systems across development and production help reduce the possibility that something will go wrong.
	
When learning analytics, a similar development environment can ensure that associated examples and exercises will work across a population of users-who may be using a wide variety of different types of operating systems. Whenever you develop modules your code will often rely upon packages that have been written by others.  These packages can provide tremendous functionality while abstracting out complexities that may not be necessary for you to undertake.  For example, packages to enable downloading of data from the Twitter Stream API or conducting a neural network analysis, but when then can be accessed through calling a specific class this can enable the complexity to be hidden.  It could be that such packages further have incorporated packages.  Such packages necessarily may need to be directly compatible with the operating system.  Further complicating the packages often have versioning with specific apps sets of code potentially conflicting with required apps.
	
This ended up being a significant issue for me the first analytics class I taught a few years ago.  I was trying to provide the students with experience interacting with a number of databases in R.  Extracting data from databases is not that complex when you use some of the available packages that handle the connection to the database.  However, I found that while the exercises has worked just fine on my Mac, it didn't work well on anyone who had a windows machine because the versions available for each operating system were different. You similarly don't want those types of issues if implementation some type of analytics based production environment. 

For that reason, we will be incorporating a number of foundational technology tools likely to be important for the data scientist working in the wild as part of the education process.  They include *Git/GitHub*, *virtual machines*,  and *the Linux command line*.

### Git/Github
Git and Github provide a Version control system and collaboration platform by which you can control versions of analyses as well as the underlying platform for doing analyses.  Git is a program that is installed on your computer that can clone a publicly available *repository* of code and transfer that information to your machine.  Github is the most popular system for sharing and managing code.  They also have an easy to use graphical user interface (GUI) for Git called GitHub called *Github Desktop* that makes managing repositories easy. 

## Before going any further, if you don't have one already, go to Github.com, sign-up, and download GitHub Desktop.  

Let's say you have an analysis pipeline that pulls sales data from your CRM and uses it in an forecasting dashboard for your production department.  That process needs consistency, such that changes to the code used to make the prediction are tracked and controlled.  If you make and update to the algorithm or the way the data is incorporated into the analysis.  You want to make sure that everyone working around this project is updated of this change (GitHub), and that there is a clear way to go back if anything goes wrong (git).  

When using Git, start with GitHub Desktop but you should also learn your way around the command line. 
  
### Virtual Machines
Over the past few years there has been an emergence of some wonderful tools for configuring your local development environment for analytics, whether you are a Mac, PC, or Linux user.  The solution involvea utilizing a local virtual machine as an alternative to installing and running programs on your local machine.  

But *what is a virtual machine?*  A virtual machine is a secondary operating system run on top of your primary operating system. You are likely running either OS X (Mac)  or Windows as your primary operating system, and it is most common to utilize a virtual machine based upon one of the Linux distributions.  This Linux distribution is the core foundation on which we will build our analytics applications, installing any necessary dependencies and ensuring that whatever your host operating system you have a consistent environment. 

### The Linux Command Line
When using a Linux Virtual machine, we won't have the same pretty and convenient GUI that we have on our Windows or Mac device. It does exist, and you can install and run everything on a Linux Desktop machine, but this creates a lot of additional overhead on your local machine, and it doesn't easily transition to a production environment.  We will have to get used to the process of utilizing a Linux command line to do what we need to do. 

*Lab 1: Build the Virtual Machine for Python and R*
In order to run the virtual machine locally, you will need to install several different programs that will be used to develop machine.
*[git](http://git-scm.com/downloads) Git is a version control system, and we will be utilizing it to share all of the updates to the configuration virtual machine as well as the associated labs and challenge problems.  Git is primarily source control for applications, but there are a wide variety of other areas in which people have started to use it.  Everything from writing and documents to analytics. 
 Install Virtualbox, Vagrant, and git now. 
* [Virtualbox](https://www.virtualbox.org/wiki/Downloads). Virtual box is the general purpose virtualizer that is able to start and maintain a virtual instance of the machine.  This will allow a linux operating system (in our case Ubuntu) to be running directly on your computer.  That way, we will all have a common operating environment to work it. 
* [Vagrant](http://www.vagrantup.com/downloads.html) Vagrant provides flexibility in enabling us to download a base linux distribution and then customize it to our needs.  This means that if we screw something up locally, we can rebuild the who thing.  We can abstract and keep files we are going to work on local, but automatically share 

To build the virtual machine, it is really quite easy.  You first will need to clone the repository holding the configuration files and others
`git clone alsjdlfjasdlfja`
Then just change to the directory and 
`>cd ******
>vagrant up`
The resulting configuration can take around 20 minutes depending on the size of your processes, but what is happening is really brilliant.  It starts by downloading a "base box" that can be used again should you ever need to rebuild the virtual machine.  It then uses something called [Chef](https://www.chef.io) to install the wide variety of different components necessary for doing analytics.  Bundles of these components are organized into [cookbooks]() that are in the in the Chef.io [supermarket](https://supermarket.chef.io).  Yes, the who thing is a bit silly, but it does help to immediately communicate the different pieces and how they are connected. 

Now if everything goes well, Vagrant & Chef will finish configuring your virtual machine and you are ready to get started!    

Lets first get to some of the common problems related to doing data science locally.   

we will be covering a wide variety of methods of installing and working with analytics programs. We will cover installation of R and Python locally, via a virtual machine,  via a Docker container, and on the cloud with [DominoData Labs](http://dominodatalab.com).  The virtual machine, the docker, container, and the cloud (Domino Data labs and the SAS academic cloud) get past the challenges of having different local environments by standardizing on a Linux based operating system. This ensures that the code examples work and challenges won't involve a lot of unnecessary trouble shooting.

The cloud is a wonderful solution for analytics, and you could make the case that things are just getting started compared to other areas.  Domino Data labs allows you to develop code locally and then deploy/share/run on the cloud.  This is a great way to share analyses with others and solidify repeatable findings. For startups, you can even write an API that uses the outcome of your analyses.   

When covering SAS examples, we will be using the SAS academic cloud.  This will simplify some aspects of our analysis and if you are at a college or university it is likely you will be able to gain access to the SAS cloud.  Cloud based development and deployment have the advantage of being able to standardize on a single set of available packages. 
#Download the SAS Virtual Machine
SAS has recently provided a virtual machine environment called SAS University Edition.  They are doing it for the same reason that we are--it makes the distribution of a software package with a wide variety of dependencies quick and easy.  Unfortunately, we can't combine our efforts with the SAS virtual machine into one, but we will be able to do quite a bit with their virtual Machine. 

To download, just sign into your SAS profile, accept the license agreement, and then complete the download. Boom! you are done. 

T

### Footnote: The Cloud and Analytics
Increasingly, the *cloud* has provided an excellent platform for sharing applications and even doing some targeted types of development.  When we refer to *analytics in the cloud,* this indicates that the computation and analyses are  conducted on a *server* rather than a *desktop*.  This difference is also important for setting up a development environment.  The cloud is the most stable but not always a flexible analysis environment. 
